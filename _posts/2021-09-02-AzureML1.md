# Tips and Tricks with sending jobs to Azure ML Compute Clusters

Recently, especially when trying out new things, one feels frustrated when things just don't go smoothly. Especially with sending jobs to Azure ML Clusters, or perhaps other providers as well where you don't have control over each and every step (i.e. you will need to simulate how the steps will go over by compiling them inside your brain or pen and paper, theoretically) hence they take longer before something works. The errors that arise include environment setup problems, incompatibility issue with packages, how to set up installation with .yml file especially when one don't really understand the whole command of conda installation such as `conda create -n rapids-21.06 -c rapidsai -c nvidia -c conda-forge rapids-blazing=21.06 python=3.7 cudatoolkit=11.0 --yes` (how to put the -c inside a yaml file, and one can tell you now one didn't manage to figure it out and still don't understand what it means as one haven't search about it), and own program errors. 

Today, one is going to share some tips and tricks on how to speed up the cycle of testing, after failing 24 times (which is, not a lot, considering Thomas Edison failed 999 times inventing the light bulb). 

First, whenever you can, **use the curated environments provided**. They not only directly skip (docker) environment building, which can takes up to 30 minutes (or even worse) (although on average around 10-20 minutes depending on build and luck. One have to say that, the totally same environment, depending on your luck, might takes just 7-8 minutes to build on a lucky day and 19-20 minutes on an unlucky day). With curated environment you skip this building and directly went into "queue" state and viola, wait for resizing, and you can now use the node. **If you need extra packages** (and they do not need to "restart the kernel" after pip install), you can do within your .py file at the top, (Python)
`import os; os.system("pip install ...")`
and that would do fine. Although if you want to keep your code clean, it is not recommend to do it this way, and during testing and debugging this would speed up so it's fine. Just remove it and put it in a yaml or requirements.txt file after sending the job to train. 

If you really need custom environment, you could use the .yaml file, or you can use `azureml.core.Environment.from_pip_requirements` with pip files (although one haven't tested how this works yet, hence no suggestions), or other methods which you could check out [here](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments) or some sample notebooks are also available if you have an ML Studio workspace, which mostly are useful although some are older notebooks and give deprecation warnings on running them. 

More preferably, create your custom environment from dockerfile. Clicking into curated environment actually shows you a dockerfile configuration on the right hand side
